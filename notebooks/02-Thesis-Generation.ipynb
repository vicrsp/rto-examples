{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Real-Time Optimization\n",
    "## Modifier Adaptation with Bayesian Optimization using EIC acquisition\n",
    "### Preliminary thesis results generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Loading the necessary packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.utils import Bunch\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "from rto.models.williams_otto import WilliamsOttoReactor_CamelHump, WilliamsOttoReactor_Branin, WilliamsOttoReactorSimplified_CamelHump, WilliamsOttoReactorSimplified_Branin\n",
    "from rto.optimization.optimizer import ModifierAdaptationOptimizer, ModelBasedOptimizer\n",
    "from rto.optimization.bayesian import ModelBasedBayesianOptimizer\n",
    "from rto.rto import RTOBayesian, RTO\n",
    "from rto.adaptation.ma_gaussian_processes import MAGaussianProcesses\n",
    "from rto.utils import generate_samples_uniform\n",
    "from rto.experiment.analysis import ExperimentAnalyzer\n",
    "\n",
    "# backup script\n",
    "!python ../scripts/create_database.py -n thesis-analysis-03 -f /mnt/d/rto_data/\n",
    "DATABASE = \"/mnt/d/rto_data/thesis-analysis-03.db\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Creating database to /mnt/d/rto_data/thesis-analysis-03.db\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Our complete model will be called the \"plant\"\n",
    "plant_branin = WilliamsOttoReactor_Branin()\n",
    "plant_camelhump = WilliamsOttoReactor_CamelHump()\n",
    "\n",
    "# And the uncertain is the \"model\"\n",
    "model_branin = WilliamsOttoReactorSimplified_Branin()\n",
    "model_camelhump = WilliamsOttoReactorSimplified_CamelHump()\n",
    "\n",
    "# define the constraints\n",
    "ubx = [5.5, 90]\n",
    "lbx = [2.5, 70]\n",
    "g_branin = np.array([0.16, 0.12])\n",
    "g_camelhump = np.array([0.16, 0.12])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "optimizer_branin = ModelBasedOptimizer(ub=ubx, lb=lbx, g=g_branin)\n",
    "optimizer_camelhump = ModelBasedOptimizer(ub=ubx, lb=lbx, g=g_camelhump)\n",
    "\n",
    "f_branin, u_branin ,_ = optimizer_branin.run(plant_branin, [])\n",
    "f_camelhump, u_camelhump ,_ = optimizer_camelhump.run(model_branin, [])\n",
    "\n",
    "f_branin_model, u_branin_model ,_ = optimizer_branin.run(model_branin, [])\n",
    "f_camelhump_model, u_camelhump_model ,_ = optimizer_camelhump.run(model_camelhump, [])\n",
    "\n",
    "print(f'Branin: u*={u_branin}, f*={f_branin}')\n",
    "print(f'Camel Hump: u*={u_camelhump}, f*={f_camelhump}')\n",
    "\n",
    "print(f'Branin (model): u*={u_branin_model}, f*={f_branin_model}')\n",
    "print(f'Camel Hump (model): u*={u_camelhump_model}, f*={f_camelhump_model}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Branin: u*=[ 4.39586571 70.88897484], f*=1.921573632520781\n",
      "Camel Hump: u*=[ 4.73763516 85.9234244 ], f*=0.3979688565197037\n",
      "Branin (model): u*=[ 4.74123808 85.93361563], f*=0.39789010666847524\n",
      "Camel Hump (model): u*=[ 5.49924863 70.0035141 ], f*=-26.700747546803775\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real-Time Optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EIC acquisition function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Branin"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Optimizer Choice"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Define the system parameters\n",
    "u_0 = u_branin_model\n",
    "iterations = 30\n",
    "initial_data_size = 5\n",
    "\n",
    "# sample some initial data\n",
    "u, y, measurements = generate_samples_uniform(model_branin, plant_branin, g_branin, u_0, initial_data_size, noise=0.0)\n",
    "initial_data_branin = Bunch(u=u, y=y, measurements=measurements)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "adaptation_bay_de = MAGaussianProcesses(model_branin, initial_data_branin, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "adaptation_bay_sqp = MAGaussianProcesses(model_branin, initial_data_branin, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "\n",
    "optimizer_bay_de = ModelBasedBayesianOptimizer(ub=ubx, lb=lbx, g=g_branin, solver={'name': 'de'}, backoff=0.0)\n",
    "optimizer_bay_sqp = ModelBasedBayesianOptimizer(ub=ubx, lb=lbx, g=g_branin, solver={'name': 'sqp'}, backoff=0.0)\n",
    "\n",
    "rto_bay_de = RTOBayesian(model_branin, plant_branin, optimizer_bay_de, adaptation_bay_de, iterations, db_file=DATABASE, name='MA-GP-Bayesian-DE-branin', noise=0.0)\n",
    "rto_bay_sqp = RTOBayesian(model_branin, plant_branin, optimizer_bay_sqp, adaptation_bay_sqp, iterations, db_file=DATABASE, name='MA-GP-Bayesian-SQP-branin', noise=0.0)\n",
    "\n",
    "u_0_feas_branin = initial_data_branin.u[-1]\n",
    "rto_bay_sqp.run(u_0_feas_branin)\n",
    "rto_bay_de.run(u_0_feas_branin)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Effect of noise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "noise = 0.01\n",
    "repetitions = 10\n",
    "\n",
    "adaptation_de_noise = MAGaussianProcesses(model_branin, initial_data_branin, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "adaptation_sqp_noise = MAGaussianProcesses(model_branin, initial_data_branin, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "\n",
    "rto_ma_sqp_noise = RTO(model_branin, plant_branin, optimizer_bay_sqp, adaptation_sqp_noise, iterations, db_file=DATABASE, name='MA-GP-Bayesian-SQP-branin+noise', noise=noise)\n",
    "rto_ma_de_noise = RTO(model_branin, plant_branin, optimizer_bay_de, adaptation_de_noise, iterations, db_file=DATABASE, name='MA-GP-Bayesian-DE-branin+noise', noise=noise)\n",
    "\n",
    "for i in range(repetitions):\n",
    "    rto_ma_sqp_noise.run(u_0_feas_branin)\n",
    "    rto_ma_de_noise.run(u_0_feas_branin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Different initial points with noise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# sample some initial data\n",
    "# generate all the data before\n",
    "n_datasets = 10\n",
    "datasets_branin = []\n",
    "for i in range(n_datasets):\n",
    "    u_i, y_i, measurements_i = generate_samples_uniform(model_branin, plant_branin, g_branin, u_0, initial_data_size, noise=noise)\n",
    "    datasets_branin.append(Bunch(u=u_i, y=y_i, measurements=measurements_i))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for i in range(n_datasets):\n",
    "    initial_dataset = datasets_branin[i]\n",
    "    adaptation_bay_de_noise = MAGaussianProcesses(model_branin, initial_dataset, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "    rto_bay_de_noise = RTOBayesian(model_branin, plant_branin, optimizer_bay_de, adaptation_bay_de_noise, iterations, db_file=DATABASE, name='MA-GP-Bayesian-DE-branin+noise-datasets', noise=noise)\n",
    "    rto_bay_de_noise.run(initial_dataset.u[-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Camel Hump"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Define the system parameters\n",
    "u_0 = u_camelhump_model\n",
    "iterations = 30\n",
    "initial_data_size = 5\n",
    "\n",
    "# sample some initial data\n",
    "u, y, measurements = generate_samples_uniform(model_camelhump, plant_camelhump, g_camelhump, u_0, initial_data_size, noise=0.0)\n",
    "initial_data_camelhump = Bunch(u=u, y=y, measurements=measurements)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "adaptation_bay_de = MAGaussianProcesses(model_camelhump, initial_data_camelhump, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "adaptation_bay_sqp = MAGaussianProcesses(model_camelhump, initial_data_camelhump, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "\n",
    "optimizer_bay_de = ModelBasedBayesianOptimizer(ub=ubx, lb=lbx, g=g_camelhump, solver={'name': 'de'}, backoff=0.0)\n",
    "optimizer_bay_sqp = ModelBasedBayesianOptimizer(ub=ubx, lb=lbx, g=g_camelhump, solver={'name': 'sqp'}, backoff=0.0)\n",
    "\n",
    "rto_bay_de = RTOBayesian(model_camelhump, plant_camelhump, optimizer_bay_de, adaptation_bay_de, iterations, db_file=DATABASE, name='MA-GP-Bayesian-DE-camelhump', noise=0.0)\n",
    "rto_bay_sqp = RTOBayesian(model_camelhump, plant_camelhump, optimizer_bay_sqp, adaptation_bay_sqp, iterations, db_file=DATABASE, name='MA-GP-Bayesian-SQP-camelhump', noise=0.0)\n",
    "\n",
    "u_0_feas_camelhump = initial_data_camelhump.u[-1]\n",
    "rto_bay_sqp.run(u_0_feas_camelhump)\n",
    "rto_bay_de.run(u_0_feas_camelhump)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Effect of noise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "noise = 0.01\n",
    "repetitions = 10\n",
    "\n",
    "adaptation_de_noise = MAGaussianProcesses(model_camelhump, initial_data_camelhump, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "adaptation_sqp_noise = MAGaussianProcesses(model_camelhump, initial_data_camelhump, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "\n",
    "rto_ma_sqp_noise = RTO(model_camelhump, plant_camelhump, optimizer_bay_sqp, adaptation_sqp_noise, iterations, db_file=DATABASE, name='MA-GP-Bayesian-SQP-camelhump+noise', noise=noise)\n",
    "rto_ma_de_noise = RTO(model_camelhump, plant_camelhump, optimizer_bay_de, adaptation_de_noise, iterations, db_file=DATABASE, name='MA-GP-Bayesian-DE-camelhump+noise', noise=noise)\n",
    "\n",
    "for i in range(repetitions):\n",
    "    rto_ma_sqp_noise.run(u_0_feas_camelhump)\n",
    "    rto_ma_de_noise.run(u_0_feas_camelhump)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Different initial points with noise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# sample some initial data\n",
    "# generate all the data before\n",
    "n_datasets = 10\n",
    "datasets_camelhump = []\n",
    "for i in range(n_datasets):\n",
    "    u_i, y_i, measurements_i = generate_samples_uniform(model_camelhump, plant_camelhump, g_camelhump, u_0, initial_data_size, noise=noise)\n",
    "    datasets_camelhump.append(Bunch(u=u_i, y=y_i, measurements=measurements_i))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for i in range(n_datasets):\n",
    "    initial_dataset = datasets_camelhump[i]\n",
    "    adaptation_bay_de_noise = MAGaussianProcesses(model_camelhump, initial_dataset, ub=ubx, lb=lbx, filter_data=True, neighbors_type='k_last')\n",
    "    rto_bay_de_noise = RTOBayesian(model_camelhump, plant_camelhump, optimizer_bay_de, adaptation_bay_de_noise, iterations, db_file=DATABASE, name='MA-GP-Bayesian-DE-camelhump+noise-datasets', noise=noise)\n",
    "    rto_bay_de_noise.run(initial_dataset.u[-1])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "340861b49ceb10eab6e90e49bcadd95c453101e2c5221b8cc6029df2c3998086"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('rto-debug': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}